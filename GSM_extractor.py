"""
AUTHOR: Jean-FranÃ§ois Nadeau
SCRIPT: GSM_extractor.py
    This script is used to extract pertinent info from a GSM native XML file from the sra database.
    It also search the targeted protein for some type of experiments like ChIP-Seq.
USAGE:
    python3 GSM_extractor.py processes path
    -processes: Integer indicating the number of paralell process to create.
    -path: Path to the directory containing the xml files. If you need to download the XML files, the path should be the word "online"
Examples:
    python3 GSM_extractor 12 xml/
    python3 GSM_extractor 8 online
NOTE: To use the online mode, please fill the config.ini files that contains the information for the Entrez query and the output directory for the xml files.
"""

import os
import sys
from multiprocessing import Pool
import read_xml
import re
from collections import OrderedDict
from functools import partial
from Bio import Entrez




""" ###############################################################################
    #                               MAIN FUNCTION                                 #
    ###############################################################################
"""
def main():
    # Read arguments

    try:
        cores=int(sys.argv[1])
        path=sys.argv[2]
        orgs=sys.argv[3:]
    except:
        print_help()
    for org in orgs:
        alias=org
        full_name={"saccer":"saccharomyces_cerevisiae","elegans":"caenorhabditis_elegans","human":"homo_sapiens","mouse":"mus_musculus","arabidopsis":"arabidopsis_thaliana","zebrafish":"danio_rerio","fly":"drosophila_melanogaster","chicken":"gallus_gallus","chimp":"pan_troglodytes","rat":"rattus_norvegicus","pombe":"schizosaccharomyces pombe"}
        #regex_dictio=get_dict(org)
        args=read_config()

        ### ONLINE MODE ###
        if path=="online":
            path=args["xml_out"]
            #clear_outdir(args["xml_out"])
            get_files(full_name[org],args,cores,alias)
        """
        print ('@INFO: Extracting metadata from xml files...', file=sys.stderr)
        path=path.rstrip("/")
        for root, dirs, files in os.walk(path):
            files=["{}/{}".format(path,filename) for filename in files]
            pool=Pool(processes=cores)
            func = partial(get_line,regex_dictio,True) 
            results=pool.map(func,files)

        print(*results, sep='\n')
        print ('@INFO: Done!', file=sys.stderr)"""
        

def get_GSM(GSE):
    GSM_list=[]
    if GSE.startswith("20"):
        GSE="GSE"+GSE.lstrip("2").lstrip("0")
        completed=False
        while not completed:
            #Avoid esearch XML reading error
            try:
                GSM_handle=get_sra_handle(GSE,"gds")
                completed=True
            except:
                pass
        for GSM in GSM_handle['IdList']:
            if GSM.startswith("30"):
                GSM="GSM"+GSM.lstrip("3").lstrip("0")
                GSM_list.append(GSM)
    return(GSM_list)


""" ###############################################################################
    #                     METADATA PROCESSING MODULES                             #
    ###############################################################################
"""
#This function checks and correct the library strategy field if needed
def check_assay(STRATEGY,attributes,title,study):
    info=" - ".join([attributes,title,study])
    names={"BREAK-SEQ":"BREAK-?SEQ","BRDU":"BRDU","ATAC-SEQ":"ATAC-?SEQ","CUT-AND-RUN":"CUT.?AND.?RUN","GRO-SEQ":"GRO-?SEQ","GRO-CAP":"GRO-?CAP","FAIRE-SEQ":"FAIRE","CHIP-EXO":"CHIP-?EXO","CHEC-SEQ":"CHEC-?SEQ","CHIP-ESPAN":"CHIP-?ESPAN"}
    for name in names:
        if re.search(names[name],info.upper())!=None:
            STRATEGY=name
    return STRATEGY


#This function checks it a control term is found within the sample title and attributes
def check_if_input(title,attributes):
    target="not_found"
    confidence=0
    attributes=re.sub(r'\([^)]*\)', '', attributes.lower().replace("tissue:wce",""))
    for att in attributes.split(" | "):
        if any(x in att for x in ["antibody:","chip:","protein:","flag tagged:","target of ip:"]):
            if any(x in att for x in ["input","mock","wce","control","igg","_in_","wce","whole cell extract", "antibody:none","epitope:none"]):
                target="INPUT"
                confidence=1
        elif "source:" in att:
            if any(x in att for x in ["input","mock","wce","control","igg","_in_","wce","whole cell extract"]):
                target="INPUT"
                confidence=5
    if re.search(r"(input|_in_|wce|whole\scell\sextract|mock|control|untagged|igg-ip)",title.lower())!=None:
        target="INPUT"
        confidence=3
    return target,confidence


# This function recieve the lists generated by the confidence_level function ordered in a confidence level order and return the first non-empty list od size 1. 
# If multiple targets, returns all targets with a confidence of 5.
# If nothing found, return not_found with a confidence of 0


#This function search for flagged terms in a given field and return all hits
def get_flagged(regex_dictio,field,flags):
    targets=[]
    for f in flags:
        if re.search(flags[f],str(field).lower()):
            flagged=re.findall(flags[f],str(field).lower())
            if flagged:
                for t in regex_dictio:
                    if re.search(regex_dictio[t], str(flagged)):
                        targets.append(t)
    return targets


# extract pertinent info from a given xml file
def get_line(regex_dictio,local,file):
    GSM=file.split("/")[-1].rstrip(".xml")
    line=read_xml.fields(file,local)
    return process_line(regex_dictio,line,GSM)

def get_strain(attributes,title):
    strain=""
    for att in attributes.lower().split(" | "):
        if any(x in att for x in ["strain:","strain name:","strain number:","cell description:"]):
            strain=att.split(":")[1]
                
    return strain

#This function search for targets in a given field
def search_all_targets(regex_dictio,field):
    hits=[]
    if field:
        for t in regex_dictio:
            if re.search(regex_dictio[t], str(field).lower()):
                hits.append(t)
    return hits


#This function search for a given target in a given field
def search_this_target(regex_dictio,field,t):
    hits=[]
    if field:
        if re.search(regex_dictio[t], str(field).lower())!=None:
            hits.append(t)
    return hits

def return_best_list(list_of_lists):
    for l in list_of_lists:
        if len(list(set(l)))==1:
            return l
    return []

def confidence1_only(regex_dictio,attributes,title,flags):
    lvl1_1,lvl1_2,lvl1_3=[],[],[]
    for att in attributes.lower().split(" | "):
        if any(x in att for x in ["antibody:","chip:","protein:","flag tagged:","target of ip:","epitope:","antibody #lot number:", "epitope tags:"]):
            flagged1=flagged2=[]
            for f in flags:
                if re.search(flags[f],att):
                    flagged1+=re.findall(flags[f],attributes.lower())
                if re.search(flags[f],title.lower()):
                    flagged2+=re.findall(flags[f],title.lower())
            for t in regex_dictio:
                lvl1_1+=search_this_target(regex_dictio,att,t)
                lvl1_2+=search_this_target(regex_dictio,flagged1,t)
                lvl1_3+=search_this_target(regex_dictio,flagged2,t)
        lvl1=return_best_list([lvl1_1,lvl1_2,lvl1_3])
    #print(lvl1,"\n\n")
    if lvl1:
        return lvl1[0],1
    else:
        return "not_found",0

#This function search for the target and fill different lists according to the confidence level of the research algorithms used"
def search_target(regex_dictio,attributes,title,flags):
    #if "Cut-and-Run_H2A" in title:
    lvl1_1,lvl1_2,lvl1_3,lvl2,lvl3,lvl4,lvl5=[],[],[],[],[],[],[]
    # CONFIDENCE_1
    for att in attributes.lower().split(" | "):
        if any(x in att for x in ["antibody:","chip:","protein:","flag tagged:","target of ip:","epitope:","antibody #lot number:", "epitope tags:"]):
            flagged1=flagged2=[]
            for f in flags:
                if re.search(flags[f],att):
                    flagged1+=re.findall(flags[f],attributes.lower())
                if re.search(flags[f],title.lower()):
                    flagged2+=re.findall(flags[f],title.lower())
            for t in regex_dictio:
                lvl1_1+=search_this_target(regex_dictio,att,t)
                lvl1_2+=search_this_target(regex_dictio,flagged1,t)
                lvl1_3+=search_this_target(regex_dictio,flagged2,t)
        lvl1=return_best_list([lvl1_1,lvl1_2,lvl1_3])
    #print(lvl1,"\n\n")
    if lvl1:
        return lvl1[0],1
    else:
        for att in attributes.lower().split(" | "):
            if any(x in att for x in ["source name:","source_name:","antibody #lot number:"]):
                source_hits=search_all_targets(regex_dictio,att)
                if len(source_hits)==1:
                    return source_hits[0],2
        # CONFIDENCE_2_TO_4
        for t in regex_dictio:
            regex=regex_dictio[t].replace(r"(\D+|$)","")+r"(?=(_|\s|-)?(ip|chip|crosslinked|protein\schip|sonication_ip|chromatin\simmuno))"
            if re.search(regex,title.lower()):
                lvl3.append(t)
            if re.search(regex_dictio[t],title.lower()):
                lvl4.append(t)
        lvl3=rm_deltas(regex_dictio,lvl3,title.lower())
        lvl4=rm_deltas(regex_dictio,lvl4,title.lower())
        lvl5=get_flagged(regex_dictio,title,flags)
        lower_conf=[lvl3,lvl4,lvl5]
        for i in range(len(lower_conf)):
            if len(list(set(lower_conf[i])))==1:
                return lower_conf[i][0],i+2
    if len(lvl4)>1 and "strain:" in attributes:
        for att in attributes.lower().split(" | "):
            if "strain:" in att:
                for t in lvl4:
                    if re.search(regex_dictio[t],att):
                        lvl4.remove(t)
        if len(lvl4)==1:
            return lvl4[0],4
    lvl6=" & ".join(lvl4)
    if lvl6:
        return lvl6,6
    else:
        return "not_found",0


# checks if the targets in a given list match a deletion patern. Returns a list of the targets that do not match in any patterns.
def rm_deltas(regex_dictio,target_list,field):
    new=[]
    for t in target_list:
        regex=r'((â|d|d\(|delta|del)+(-|_)?'+regex_dictio[t]+'|'+regex_dictio[t].replace(r"(\D+|$)","")+r'-?(-as|Î´|\stail\sdelete|del|\{delta\}|â|aa|d|-(\s|_|$)))'
        if not re.search(regex,field.lower()):
            new.append(t)
    return new

def custom_fixes(field):
    terms=["red1 chip","jhd2_chip_seq_yar","wt_chip_seq_yar","yng2-wa"]
    for term in terms:
        field=field.lower().replace(term,"")
    return field

# Process line according to the library strategy
def process_line(regex_dictio,line,GSM):
    GSM=get_GEO_ID(line)
    strain=""
    if GSM:
        flags={"FLAG":r"([^_\s]+-[0-9]*x?flag|[0-9]*x?flag-[^_\s]+|flag)","MYC":r"([^-_\s]+(-c)?-[0-9]*x?myc|(c-)?[0-9]*x?myc-[^_\s]+|(c-)?myc|9e10)","V5":r"([^_\s]+-[0-9]*x?v5|[0-9]*x?v5-[^_\s]+|v5)","TAP":r"([^_\s]+-[0-9]*x?tap|[0-9]*x?tap-[^_\s]+|tap)","HA":r"([^_\s]+-[0-9]*x?ha|[0-9]*x?ha-[^_\s]+|ha)","GFP":r"([^_\s]+-[0-9]*x?gfp|[0-9]*x?gfp-[^_\s]+|gfp)","T7":r"([^_\s]+-[0-9]*x?t7|[0-9]*x?t7-[^_\s]+|t7)"}
        joined=" - ".join([line["SAMPLE_NAME"],line["SAMPLE_TITLE"],line["EXP_TITLE"],line["ATTRIBUTES"],line["STUDY_TITLE"],line["LIB_STRAT"]])
        if any(x in joined.lower() for x in ["chip-seq","chip-exo","mnase-seq","chec-seq","cut-and-run"]) or line["LIB_STRAT"].lower()=="other":
            line["LIB_STRAT"]=check_assay(line["LIB_STRAT"],line["ATTRIBUTES"],line["SAMPLE_TITLE"],line['STUDY_TITLE'])
            if line["LIB_STRAT"].lower()=="mnase-seq":
                target,confidence=check_if_input(line["SAMPLE_TITLE"],line["ATTRIBUTES"])
                if confidence==0:
                    target,confidence=confidence1_only(regex_dictio,custom_fixes(line["ATTRIBUTES"]),custom_fixes(line["SAMPLE_TITLE"]),flags)
                    strain=get_strain(line["ATTRIBUTES"],line["SAMPLE_TITLE"])

            elif any(x in line["LIB_STRAT"].lower() for x in ["chip-seq","chip-exo","chec-seq","cut-and-run", "brdu"]):
                if "1st ip:" in line["ATTRIBUTES"].lower():
                    hits=[]
                    info=line["SAMPLE_TITLE"].split("-")
                    pair=" ".join(info[1:])
                    strain=" ".join(info[0])
                    for t in regex_dictio:
                        if re.search(regex_dictio[t],pair.lower()):
                            hits.append(t)
                    if "input" in pair.lower():
                        hits.append("input")
                    target,confidence="/".join(hits),1
                else:
                    target,confidence=check_if_input(line["SAMPLE_TITLE"],line["ATTRIBUTES"])
                    if confidence==0:
                        target,confidence=search_target(regex_dictio,custom_fixes(line["ATTRIBUTES"]),custom_fixes(line["SAMPLE_TITLE"]),flags)
                        strain=get_strain(line["ATTRIBUTES"],line["SAMPLE_TITLE"])
            else:
                confidence=0
                target=line["LIB_STRAT"]
        else:
            target=line["LIB_STRAT"]
            confidence=0
        if line["LIB_STRAT"].lower()=="mnase-seq" and confidence in [0,6]:
            target="mnase-seq"
        line["STRAIN"]=strain
        return "\t".join([GSM,line["LIB_STRAT"],str(confidence),target])

def get_GEO_ID(line):
    GSM=list(set(re.findall("GSM[0-9]+",line["SAMPLE_NAME"])))
    return " | ".join(GSM)




""" ###############################################################################
    #                              CONFIG MODULES                                 #
    ###############################################################################
"""
# Clear the xml output directory
def clear_outdir(dirPath):
    if not os.path.exists(dirPath):
        os.makedirs(dirPath)
    fileList = os.listdir(dirPath)
    [ os.remove(os.path.abspath(os.path.join(dirPath,fileName))) for fileName in fileList ]


#Build and return the regex_dict
def get_dict(org):
    org_dictio={}
    common_dictio={}
    lines=[]
    f="dictios/{}.dict".format(org)
    with open(f,"r") as f:
        lines=f.readlines()
    for line in lines:
        if line!="\n" and line!="":
            line=line.rstrip("\n").split(",")
            org_dictio[line[0]]=line[1]
    with open("dictios/common.dict","r") as f:
        lines=f.readlines()
    for line in lines:
        if line!="\n" and line!="":
            line=line.rstrip("\n").split(",")
            common_dictio[line[0]]=line[1]
    targets=OrderedDict(org_dictio)
    targets.update(OrderedDict(common_dictio))
    return targets


def print_help():
    text="""SCRIPT: GSM_extractor.py
    This script is used to extract pertinent info from a GSM native XML file from the sra database.
    It also search the targeted protein for some type of experiments like ChIP-Seq.

    USAGE:
        python3 GSM_extractor.py processes path
        -processes: Integer indicating the number of paralell process to create. Default is 4.
        -path: Path to the directory containing the xml files. If you need to download the XML files, the path should be the word "online"
    Examples:
        python3 GSM_extractor 12 xml/
        python3 GSM_extractor 8 online

    NOTE: To use the online mode, please fill the config.ini files that contains the information for the Entrez query and the output directory for the xml files."""
    print(text)
    quit()


# Read and return the config file
def read_config():
    params=""
    args={}
    with open("config.ini", "r") as conf:
        params=conf.readlines()
    for line in params:
        if not line.startswith("#"):
            if "=" in line:
                line=line.rstrip("\n").split("=")
                args[line[0]]=line[1]
            else:
                print("ERROR: invalid config file")
                quit()
    return args





""" ###############################################################################
    #                           ONLINE MODE MODULES                               #
    ###############################################################################
"""
#Build and return a query for each month of the given year
def build_query(args, org):
    #adding the org
    query=org+"[ORGN] "
    #adding the search terms:
    if "Search_terms" in args:
        query+="AND {}".format(" AND ".join(args['Search_terms'].split(",")))
    #adding the filter out terms:
    if "Filter_out" in args:
        query+=" NOT ( {} )".format(" OR ".join(args["Filter_out"].split(",")))
    #adding the date
    query+=" AND {}[PDAT]".format(args['Date_range'])
    if "Custom" in args:
        query+=" "+args['Custom']
    return query


# Dowload and process the given xml file
def efetch(xml_out,ID):
    completed=False
    while not completed:
        #avoid multiprocess error "cannot serialize '_io.BufferedReader' object"
        try:
            sample=Entrez.efetch(db="sra", id=ID, format="native").readlines()
            filename="{}/{}.xml".format(xml_out,ID)
            with open(filename,"w") as f:
                f.write("".join(sample))
            completed=True
        except:
            pass
            
            print ('@ERROR: Multiprocessing error, retrying...', file=sys.stderr)

# Send esearch query and return the resulting dictionary (containing the count, id of the samples etc...)
def get_sra_handle(query, database):
    handle = Entrez.esearch(db=database,retmax=1000000, term=query)
    dic=Entrez.read(handle)
    return dic

def get_files(org,args,cores,alias):
    already_there=[]
    for root, dirs, files in os.walk(alias):
        for name in files:
            path=alias+"/"+name
            if os.stat(path).st_size>0:
                already_there.append(name.rstrip(".xml)"))

    query=""
    print ('@INFO: Entering online mode, processing ',org, file=sys.stderr)
    str_list=[]
    Entrez.email = args["Entrez_email"]
    query=build_query(args,org)
    print ('@INFO: Query:',query, file=sys.stderr)
    print ('@INFO: Collecting the GEO series...', file=sys.stderr)
    GSE_handle=get_sra_handle(query,"gds")
    GSE_pool=Pool(processes=cores)
    print ('@INFO: Collecting the GEO sample IDs...', file=sys.stderr)
    l=GSE_pool.map(get_GSM,list(GSE_handle['IdList']))
    GSE_pool.close()
    GSM_list = [str(item) for sublist in l for item in sublist]
    print ('@INFO: Associating the GSM ID with the SRA ID...', file=sys.stderr)
    chunks = [GSM_list[x:x+5000] for x in range(0, len(GSM_list), 5000)]
    print ('@INFO: Downloading xml files from the SRA database...', file=sys.stderr)
    for chunk in chunks:
        SRA_handle=get_sra_handle(" OR ".join(chunk),"sra")
        ID_list=list(set(SRA_handle['IdList']))
        for n in already_there:
            if n in ID_list:
                ID_list.remove(n)
        online_pool=Pool(processes=cores)
        func=partial(efetch,args["xml_out"])
        online_pool.map(func,ID_list)
        online_pool.close()



if __name__ == "__main__":
    main()
