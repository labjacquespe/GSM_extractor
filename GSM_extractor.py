"""
AUTHOR: Jean-François Nadeau
SCRIPT: GSM_extractor.py
    This script is used to extract pertinent info from a GSM native XML file from the sra database.
    It also search the targeted protein for some type of experiments like ChIP-Seq.
USAGE:
    python3 GSM_extractor.py processes path
    -processes: Integer indicating the number of paralell process to create.
    -path: Path to the directory containing the xml files. If you need to download the XML files, the path should be the word "online"
Examples:
    python3 GSM_extractor 12 xml/
    python3 GSM_extractor 8 online
NOTE: To use the online mode, please fill the config.ini files that contains the information for the Entrez query and the output directory for the xml files.
"""

import os
import sys
from multiprocessing import Pool
import read_xml
import re
from collections import OrderedDict
from functools import partial
from Bio import Entrez




""" ###############################################################################
    #                               MAIN FUNCTION                                 #
    ###############################################################################
"""
def main():
    # Read arguments
    regex_dictio=get_dict("saccharomyces_cerevisiae")
    args=read_config()
    try:
        cores=int(sys.argv[1])
        path=sys.argv[2]
    except:
        print_help()
    ### ONLINE MODE ###
    if path=="online":
        clear_outdir("xml_directory")
        Entrez.email = args["Entrez_email"]
        xml_out=args["xml_out"]
        for org in args["Organisms"].split(","):
            query=build_query(args,org)
            print(query)
            results=online_mode(regex_dictio,query,cores,xml_out)
            #pool=Pool(processes=min(cores,len(years)))
            #func=partial(pool_query,regex_dictio,args,org,cores,xml_out)
            #pool.map(func,years)

                
    ### LOCAL MODE ###
    else:
        path=path.rstrip("/")
        for root, dirs, files in os.walk(path):
            files=["{}/{}".format(path,filename) for filename in files]
            pool=Pool(processes=cores)
            func = partial(get_line,regex_dictio,True) 
            results=pool.map(func,files)

    print(*results, sep='\n')


""" ###############################################################################
    #                     METADATA PROCESSING MODULES                             #
    ###############################################################################
"""
#This function checks and correct the library strategy field if needed
def check_assay(STRATEGY,attributes,title,study):
    info=" - ".join([attributes,title,study])
    names={"BREAK-SEQ":"BREAK-?SEQ","BRDU":"BRDU","ATAC-SEQ":"ATAC-?SEQ","CUT-AND-RUN":"CUT.?AND.?RUN","FAIRE-SEQ":"FAIRE","CHIP-EXO":"CHIP-?EXO","CHEC-SEQ":"CHEC-?SEQ","CHIP-ESPAN":"CHIP-?ESPAN"}
    for name in names:
        if re.search(names[name],info.upper())!=None:
            STRATEGY=name
    return STRATEGY


#This function checks it a control term is found within the sample title and attributes
def check_if_input(title,attributes):
    target="not_found"
    confidence=0
    attributes=re.sub(r'\([^)]*\)', '', attributes.lower().replace("tissue:wce",""))
    for att in attributes.split(" | "):
        if any(x in att for x in ["antibody:","chip:","protein:","flag tagged:","target of ip:"]):
            if any(x in att for x in ["input","mock","wce","control","igg","_in_","wce","whole cell extract", "antibody:none","epitope:none"]):
                target="INPUT"
                confidence=1
        elif "source:" in att:
            if any(x in att for x in ["input","mock","wce","control","igg","_in_","wce","whole cell extract"]):
                target="INPUT"
                confidence=5
    if re.search(r"(input|_in_|wce|whole\scell\sextract|mock|control|untagged)",title.lower())!=None:
        target="INPUT"
        confidence=3
    return target,confidence


# This function recieve the lists generated by the confidence_level function ordered in a confidence level order and return the first non-empty list od size 1. 
# If multiple targets, returns all targets with a confidence of 5.
# If nothing found, return not_found with a confidence of 0


#This function search for flagged terms in a given field and return all hits
def get_flagged(regex_dictio,field,flags):
    targets=[]
    for f in flags:
        if re.search(flags[f],str(field).lower()):
            flagged=re.findall(flags[f],str(field).lower())
            if flagged:
                for t in regex_dictio:
                    if re.search(regex_dictio[t], str(flagged)):
                        targets.append(t)
    return targets


# extract pertinent info from a given xml file
def get_line(regex_dictio,local,file):
    line=read_xml.fields(file,local)
    return process_line(regex_dictio,line)

def get_strain(attributes,title):
    strain=""
    for att in attributes.lower().split(" | "):
        if any(x in att for x in ["strain:","strain name:","strain number:","cell description:"]):
            strain=att.split(":")[1]
                
    return strain

#This function search for targets in a given field
def search_all_targets(regex_dictio,field):
    hits=[]
    if field:
        for t in regex_dictio:
            if re.search(regex_dictio[t], str(field).lower()):
                hits.append(t)
    return hits


#This function search for a given target in a given field
def search_this_target(regex_dictio,field,t):
    hits=[]
    if field:
        if re.search(regex_dictio[t], str(field).lower())!=None:
            hits.append(t)
    return hits

def return_best_list(list_of_lists):
    for l in list_of_lists:
        if len(list(set(l)))==1:
            return l
    return []

#This function search for the target and fill different lists according to the confidence level of the research algorithms used"
def search_target(regex_dictio,attributes,title,flags):
    #if "Cut-and-Run_H2A" in title:
    lvl1_1,lvl1_2,lvl1_3,lvl2,lvl3,lvl4,lvl5=[],[],[],[],[],[],[]
    # CONFIDENCE_1
    if "1st ip:" in attributes.lower():
        hits=[]
        pair=" ".join(title.split("-")[1:])
        for t in regex_dictio:
            if re.search(regex_dictio[t],pair.lower()):
                hits.append(t)
        if "input" in pair.lower():
            hits.append("input")
        return "/".join(hits),1
    for att in attributes.lower().split(" | "):
        att=custom_fixes(att)
        if any(x in att for x in ["antibody:","chip:","protein:","flag tagged:","target of ip:","epitope:","antibody #lot number:", "epitope tags:"]):
            flagged1=flagged2=[]
            for f in flags:
                if re.search(flags[f],att):
                    flagged1+=re.findall(flags[f],attributes.lower())
                if re.search(flags[f],title.lower()):
                    flagged2+=re.findall(flags[f],title.lower())
            for t in regex_dictio:
                lvl1_1+=search_this_target(regex_dictio,att,t)
                lvl1_2+=search_this_target(regex_dictio,flagged1,t)
                lvl1_3+=search_this_target(regex_dictio,flagged2,t)
        lvl1=return_best_list([lvl1_1,lvl1_2,lvl1_3])
    #print(lvl1,"\n\n")
    if lvl1:
        return lvl1[0],1
    else:
        for att in attributes.lower().split(" | "):
            if any(x in att for x in ["source name:","source_name:","antibody #lot number:"]):
                att=custom_fixes(att)
                source_hits=search_all_targets(regex_dictio,att)
                if len(source_hits)==1:
                    return source_hits[0],2
        # CONFIDENCE_2_TO_4
        for t in regex_dictio:
            regex=regex_dictio[t].replace(r"(\D+|$)","")+r"(?=(_|\s|-)?(ip|chip|crosslinked|protein\schip|sonication_ip|chromatin\simmuno))"
            if re.search(regex,title.lower()):
                lvl3.append(t)
            if re.search(regex_dictio[t],title.lower()):
                lvl4.append(t)
        lvl3=rm_deltas(regex_dictio,lvl3,custom_fixes(title.lower()))
        lvl4=rm_deltas(regex_dictio,lvl4,custom_fixes(title.lower()))
        lvl5=get_flagged(regex_dictio,title,flags)
        lower_conf=[lvl3,lvl4,lvl5]
        for i in range(len(lower_conf)):
            if len(list(set(lower_conf[i])))==1:
                return lower_conf[i][0],i+2
    return "not_found",0


# checks if the targets in a given list match a deletion patern. Returns a list of the targets that do not match in any patterns.
def rm_deltas(regex_dictio,target_list,field):
    new=[]
    for t in target_list:
        regex=r'((∆|d|d\(|delta|del)+(-|_)?'+regex_dictio[t]+'|'+regex_dictio[t].replace(r"(\D+|$)","")+r'-?(δ|\stail\sdelete|del|\{delta\}|∆|aa|d|-(\s|_|$)))'
        if not re.search(regex,field.lower()):
            new.append(t)
    return new

def custom_fixes(field):
    terms=["red1 chip","jhd2_chip_seq_yar","wt_chip_seq_yar","yng2-wa"]
    for term in terms:
        field=field.lower().replace(term,"")
    return field

# Process line according to the library strategy
def process_line(regex_dictio,line):
    strain=""
    GSM=get_GSM(line)
    if GSM:
        flags={"FLAG":r"([^_\s]+-[0-9]*x?flag|[0-9]*x?flag-[^_\s]+|flag)","MYC":r"([^-_\s]+(-c)?-[0-9]*x?myc|(c-)?[0-9]*x?myc-[^_\s]+|(c-)?myc|9e10)","V5":r"([^_\s]+-[0-9]*x?v5|[0-9]*x?v5-[^_\s]+|v5)","TAP":r"([^_\s]+-[0-9]*x?tap|[0-9]*x?tap-[^_\s]+|tap)","HA":r"([^_\s]+-[0-9]*x?ha|[0-9]*x?ha-[^_\s]+|ha)","GFP":r"([^_\s]+-[0-9]*x?gfp|[0-9]*x?gfp-[^_\s]+|gfp)","T7":r"([^_\s]+-[0-9]*x?t7|[0-9]*x?t7-[^_\s]+|t7)"}
        joined=" - ".join([line["SAMPLE_NAME"],line["SAMPLE_TITLE"],line["EXP_TITLE"],line["ATTRIBUTES"],line["STUDY_TITLE"],line["LIB_STRAT"]])
        if any(x in joined.lower() for x in ["chip-seq","chip-exo","mnase-seq","chec-seq","cut-and-run"]) or line["LIB_STRAT"].lower()=="other":
            line["LIB_STRAT"]=check_assay(line["LIB_STRAT"],line["ATTRIBUTES"],line["SAMPLE_TITLE"],line['STUDY_TITLE'])
            if any(x in line["LIB_STRAT"].lower() for x in ["chip-seq","chip-exo","mnase-seq","chec-seq","cut-and-run"]):
                target,confidence=check_if_input(line["SAMPLE_TITLE"],line["ATTRIBUTES"])
                if confidence==0:
                    target,confidence=search_target(regex_dictio,line["ATTRIBUTES"],line["SAMPLE_TITLE"],flags)
                    strain=get_strain(line["ATTRIBUTES"],line["SAMPLE_TITLE"])
            else:
                confidence=0
                target=line["LIB_STRAT"]
        else:
            target=line["LIB_STRAT"]
            confidence=0
        if line["LIB_STRAT"].lower()=="mnase-seq" and confidence in [0,5]:
            target="mnase-seq"
        line["STRAIN"]=strain
        return "\t".join([GSM,line["LIB_STRAT"],str(confidence),target])

def get_GSM(line):
    fields=[line['LIB_NAME'],line['SAMPLE_NAME'],line['SAMPLE_TITLE']," - ".join(line)]
    for field in fields:
        GSM=list(set(re.findall("GSM[0-9]+",field)))
        if len(GSM)==1:
            return GSM[0]
    return None




""" ###############################################################################
    #                              CONFIG MODULES                                 #
    ###############################################################################
"""
# Clear the xml output directory
def clear_outdir(dirPath):
    if not os.path.exists(dirPath):
        os.makedirs(dirPath)
    fileList = os.listdir(dirPath)
    [ os.remove(os.path.abspath(os.path.join(dirPath,fileName))) for fileName in fileList ]


#Build and return the regex_dict
def get_dict(org):
    org_dictio={}
    common_dictio={}
    lines=[]
    f=org+".dict"
    with open(f,"r") as f:
        lines=f.readlines()
    for line in lines:
        if line!="\n" and line!="":
            line=line.rstrip("\n").split(",")
            org_dictio[line[0]]=line[1]
    with open("common.dict","r") as f:
        lines=f.readlines()
    for line in lines:
        if line!="\n" and line!="":
            line=line.rstrip("\n").split(",")
            common_dictio[line[0]]=line[1]
    targets=OrderedDict(org_dictio)
    targets.update(OrderedDict(common_dictio))
    return targets


def print_help():
    text="""SCRIPT: GSM_extractor.py
    This script is used to extract pertinent info from a GSM native XML file from the sra database.
    It also search the targeted protein for some type of experiments like ChIP-Seq.

    USAGE:
        python3 GSM_extractor.py processes path
        -processes: Integer indicating the number of paralell process to create. Default is 4.
        -path: Path to the directory containing the xml files. If you need to download the XML files, the path should be the word "online"
    Examples:
        python3 GSM_extractor 12 xml/
        python3 GSM_extractor 8 online

    NOTE: To use the online mode, please fill the config.ini files that contains the information for the Entrez query and the output directory for the xml files."""
    print(text)
    quit()


# Read and return the config file
def read_config():
    params=""
    args={}
    with open("config.ini", "r") as conf:
        params=conf.readlines()
    for line in params:
        if not line.startswith("#"):
            if "=" in line:
                line=line.rstrip("\n").split("=")
                args[line[0]]=line[1]
            else:
                print("ERROR: invalid config file")
                quit()
    return args





""" ###############################################################################
    #                           ONLINE MODE MODULES                               #
    ###############################################################################
"""
#Build and return a query for each month of the given year
def build_query(args, org):
    #adding the org
    query=org+"[ORGN] "
    #adding the search terms:
    if "Search_terms" in args:
        query+="AND {}".format(" AND ".join(args['Search_terms'].split(",")))
    #adding the filter out terms:
    if "Filter_out" in args:
        query+=" NOT ( {} )".format(" OR ".join(args["Filter_out"].split(",")))
    #adding the date
    query+=" AND {}[PDAT]".format(args['Date_range'])
    if "Custom" in args:
        query+=" "+args['Custom']
    return query


# Dowload and process the given xml file
def efetch(regex_dictio,xml_out,ID):
    xml_out=xml_out.rstrip("/")
    sample=Entrez.efetch(db="sra", id=ID, format="native").readlines()
    GSM=list(set(re.findall("GSM[0-9]+","".join(sample))))
    if len(GSM)==1:
        filename="{}/{}.xml".format(xml_out,GSM[0])
        if os.path.isfile(filename):
            number=2
            temp=filename
            while os.path.isfile(temp):
                temp="{}_{}.xml".format(filename.rstrip(".xml"),number)
                number+=1
            filename=temp
        with open(filename,"w") as f:
            f.write("".join(sample))
        return get_line(regex_dictio,False,sample)

# Send esearch query and return the resulting dictionary (containing the count, id of the samples etc...)
def get_sra_handle(query, database):
    handle = Entrez.esearch(db=database,retmax=1000000, term=query)
    dic=Entrez.read(handle)
    return dic

# Process queries generated by build_query
def online_mode(regex_dictio,query,cores,xml_out):
    results=[]
    #Ajusting the month range if the user specified it
    esearch_dic=get_sra_handle(query, "sra")
    if int(esearch_dic["Count"])<cores:
        cores=int(esearch_dic["Count"])
    if str(esearch_dic["Count"])!="0":
        if esearch_dic['IdList']:
            pool=Pool(processes=cores)
            func=partial(efetch,regex_dictio,xml_out)
            results=pool.map(func,esearch_dic['IdList'])
    return results

#def pool_query(regex_dictio,args,org,cores,xml_out,year):
#    query_list=build_query(args, org, str(year))
#    online_mode(regex_dictio,query_list,cores,xml_out)



if __name__ == "__main__":
    main()